{
    "id": "vqa",
    "name": "Visual Question Answering",
    "description": "Visual Question Answering (VQA) is the task of generating a answer in response to a natural language question about the contents of an image. VQA models are typically trained and evaluated on datasets such as VQA2.0, GQA, Visual7W and VizWiz.",
    "expected_inputs": "The task requires an input image and a corresponding free text question about the image.",
    "expected_outputs": "A free text answer.",
    "scope_and_limitations": null,
    "examples": [
        {
            "image" : "https://storage.googleapis.com/allennlp-public-data/vqav2/vqa-examples/baseball_game.jpg",
            "question" : "What game are they playing?"
        },
        {
            "image": "https://storage.googleapis.com/allennlp-public-data/vqav2/vqa-examples/bus_stop.jpg",
            "question": "What are the people waiting for?"
        },
        {
            "image": "https://storage.googleapis.com/allennlp-public-data/vqav2/vqa-examples/kitchen.jpg",
            "question": "What is in the bowls on the island?"
        },
        {
            "image": "https://storage.googleapis.com/allennlp-public-data/vqav2/vqa-examples/living_room.jpg",
            "question": "What color is the pillow in the middle?"
        }
    ]
}
