{
    "id": "pair-classification-roberta-snli",
    "registered_model_name": "basic_classifier",
    "registered_predictor_name": "textual_entailment",
    "display_name": "RoBERTa SNLI",
    "task_id": "textual_entailment",
    "model_details": {
        "description": "This `Model` implements a basic text classifier. The text is embedded into a text field using a RoBERTa-large model. The resulting sequence is pooled using a cls_pooler `Seq2VecEncoder` and then passed to a linear classification layer, which projects into the label space.",
        "short_description": "RoBERTa finetuned on SNLI.",
        "developed_by": "Liu et al",
        "contributed_by": "Dirk Groeneveld",
        "date": "2020-07-29",
        "version": "1",
        "model_type": "RoBERTa",
        "paper": {
            "citation": "\n@article{Liu2019RoBERTaAR,\ntitle={RoBERTa: A Robustly Optimized BERT Pretraining Approach},\nauthor={Y. Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and M. Lewis and Luke Zettlemoyer and Veselin Stoyanov},\njournal={ArXiv},\nyear={2019},\nvolume={abs/1907.11692}}\n",
            "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach (Liu et al)",
            "url": "https://api.semanticscholar.org/CorpusID:198953378"
        },
        "license": null,
        "contact": "allennlp-contact@allenai.org"
    },
    "intended_use": {
        "primary_uses": null,
        "primary_users": null,
        "out_of_scope_use_cases": null
    },
    "factors": {
        "relevant_factors": null,
        "evaluation_factors": null
    },
    "metrics": {
        "model_performance_measures": "Accuracy",
        "decision_thresholds": null,
        "variation_approaches": null
    },
    "evaluation_data": {
        "dataset": {
            "name": "Stanford Natural Language Inference (SNLI) dev set",
            "url": "https://nlp.stanford.edu/projects/snli/",
            "processed_url": "https://allennlp.s3.amazonaws.com/datasets/snli/snli_1.0_test.jsonl"
        },
        "motivation": null,
        "preprocessing": null
    },
    "training_data": {
        "dataset": {
            "name": "Stanford Natural Language Inference (SNLI) train set",
            "url": "https://nlp.stanford.edu/projects/snli/",
            "processed_url": "https://allennlp.s3.amazonaws.com/datasets/snli/snli_1.0_train.jsonl"
        },
        "motivation": null,
        "preprocessing": null
    },
    "quantitative_analyses": {
        "unitary_results": "Net Neutral: 0.49562665820121765, Fraction Neutral: 0.5068705677986145, Threshold:0.5: 0.47600528597831726, Threshold:0.7: 0.3036800026893616",
        "intersectional_results": null
    },
    "model_caveats_and_recommendations": {
        "caveats_and_recommendations": null
    },
    "model_ethical_considerations": {
        "ethical_considerations": null
    },
    "model_usage": {
        "archive_file": "snli-roberta.2021-03-11.tar.gz",
        "training_config": "pair_classification/snli_roberta.jsonnet",
        "install_instructions": "pip install allennlp==2.1.0 allennlp-models==2.1.0"
    }
}