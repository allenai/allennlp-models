{
    "id": "rc-naqanet",
    "registered_model_name": "naqanet",
    "registered_predictor_name": null,
    "display_name": "Numerically Augmented QA Net",
    "task_id": "rc",
    "model_details": {
        "description": "An augmented version of QANet model with some rudimentary numerical reasoning abilities. The main idea here is that instead of just predicting a passage span after doing all of the QANet modeling stuff, we add several different 'answer abilities': predicting a span from the question, predicting a count, or predicting an arithmetic expression.  Near the end of the QANet model, we have a variable that predicts what kind of answer type we need, and each branch has separate modeling logic to predict that answer type.  We then marginalize over all possible ways of getting to the right answer through each of these answer types.",
        "short_description": "An augmented version of QANet that adds rudimentary numerical reasoning ability, trained on DROP (Dua et al., 2019), as published in the original DROP paper.",
        "developed_by": "Dua et al",
        "contributed_by": null,
        "date": "2020-02-19",
        "version": "2",
        "model_type": "QANet",
        "paper": {
            "citation": "\n@inproceedings{Dua2019DROPAR,\ntitle={DROP: A Reading Comprehension Benchmark Requiring Discrete Reasoning Over Paragraphs},\nauthor={Dheeru Dua and Yizhong Wang and Pradeep Dasigi and Gabriel Stanovsky and Sameer Singh and Matt Gardner},\nbooktitle={NAACL-HLT},\nyear={2019}}\n",
            "title": "DROP: A Reading Comprehension Benchmark Requiring Discrete Reasoning Over Paragraphs",
            "url": "https://api.semanticscholar.org/CorpusID:67855846"
        },
        "license": null,
        "contact": "allennlp-contact@allenai.org"
    },
    "intended_use": {
        "primary_uses": null,
        "primary_users": null,
        "out_of_scope_use_cases": null
    },
    "factors": {
        "relevant_factors": null,
        "evaluation_factors": null
    },
    "metrics": {
        "model_performance_measures": "Exact Match and F1-score",
        "decision_thresholds": null,
        "variation_approaches": null
    },
    "evaluation_data": {
        "dataset": {
            "name": "DROP",
            "url": "https://allennlp.org/drop",
            "processed_url": "https://s3-us-west-2.amazonaws.com/allennlp/datasets/drop/drop_dataset.zip!drop_dataset/drop_dataset_dev.json"
        },
        "motivation": null,
        "preprocessing": null
    },
    "training_data": {
        "dataset": {
            "name": "DROP",
            "url": "https://allennlp.org/drop",
            "processed_url": "https://s3-us-west-2.amazonaws.com/allennlp/datasets/drop/drop_dataset.zip!drop_dataset/drop_dataset_train.json"
        },
        "motivation": null,
        "preprocessing": null
    },
    "quantitative_analyses": {
        "unitary_results": "Validation F1-score: 0.509, Exact Match: 0.473",
        "intersectional_results": null
    },
    "model_caveats_and_recommendations": {
        "caveats_and_recommendations": null
    },
    "model_ethical_considerations": {
        "ethical_considerations": null
    },
    "model_usage": {
        "archive_file": "naqanet-2021.02.26.tar.gz",
        "training_config": "rc/naqanet.jsonnet",
        "install_instructions": "pip install allennlp==2.1.0 allennlp-models==2.1.0"
    }
}