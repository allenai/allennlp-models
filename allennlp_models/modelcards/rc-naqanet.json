{
    "id": "rc-naqanet",
    "registered_model_name": "naqanet",
    "registered_predictor_name": null,
    "display_name": "Numerically Augmented QA Net",
    "task_id": "rc",
    "archive_file": "naqanet-2020.02.19.tar.gz",
    "model_details": {
        "description": "An augmented version of QANet model with some rudimentary numerical reasoning abilities.
                        The main idea here is that instead of just predicting a passage span after doing all of the
                        QANet modeling stuff, we add several different 'answer abilities': predicting a span from the
                        question, predicting a count, or predicting an arithmetic expression.  Near the end of the
                        QANet model, we have a variable that predicts what kind of answer type we need, and each branch
                        has separate modeling logic to predict that answer type.  We then marginalize over all possible
                        ways of getting to the right answer through each of these answer types.",
        "short_description": "An augmented version of QANet that adds rudimentary numerical reasoning ability, trained on DROP (Dua et al., 2019), as published in the original DROP paper.",
        "developed_by": "Dua et al",
        "contributed_by": null,
        "date": "2020-02-19",
        "version": "1",
        "model_type": "QANet",
        "paper": "[DROP: A Reading Comprehension Benchmark Requiring Discrete Reasoning Over Paragraphs](https://api.semanticscholar.org/CorpusID:67855846)",
        "citation": "@inproceedings{Dua2019DROPAR,
                     title={DROP: A Reading Comprehension Benchmark Requiring Discrete Reasoning Over Paragraphs},
                     author={Dheeru Dua and Yizhong Wang and Pradeep Dasigi and Gabriel Stanovsky and Sameer Singh and Matt Gardner},
                     booktitle={NAACL-HLT},
                     year={2019}}",
        "license": null,
        "contact": "allennlp-contact@allenai.org",
        "training_config": null,
    },
    "intended_use": {
        "primary_uses": null,
        "primary_users": null,
        "out_of_scope_use_cases": null
    },
    "factors": {
        "relevant_factors": null,
        "evaluation_factors": null
    },
    "metrics": {
        "model_performance_measures": "Exact Match and F1-score",
        "decision_thresholds": null,
        "variation_approaches": null
    },
    "evaluation_data": {
        "dataset": "[DROP](https://allennlp.org/drop)",
        "motivation": null,
        "preprocessing": null
    },
    "training_data": {
        "dataset": "[DROP](https://allennlp.org/drop)",
        "motivation": null,
        "preprocessing": null
    },
    "quantitative_analyses": {
        "unitary_results": null,
        "intersectional_results": null
    },
    "ethical_considerations": {
        "ethical_considerations": null
    },
    "caveats_and_recommendations": {
        "caveats_and_recommendations": null
    }
}
